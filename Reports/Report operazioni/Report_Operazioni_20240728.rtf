{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 .SFNS-Bold;\f1\fnil\fcharset0 .SFNS-Regular;\f2\froman\fcharset0 TimesNewRomanPSMT;
}
{\colortbl;\red255\green255\blue255;\red14\green14\blue14;}
{\*\expandedcolortbl;;\cssrgb\c6700\c6700\c6700;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl324\slmult1\pardirnatural\partightenfactor0

\f0\b\fs28 \cf2 Report: Operations on 2024-07-28
\f1\b0 \
\

\f0\b Summary:
\f1\b0 \
On July 28, 2024, several significant steps were undertaken in the training and evaluation of a machine learning model focused on classifying archaeological sites based on different land cover categories. Below is a detailed summary of the operations, challenges faced, and key advancements made.\
\

\f0\b Operations:
\f1\b0 \
\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 	1.	
\f0\b Normalization of Data:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Normalized images across various categories, ensuring uniformity in input data. Images were resized and standardized for use in the model.\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 	2.	
\f0\b Model Training:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Conducted training for each class within the dataset using separate directories for different types of archaeological sites.\
	\'95	Implemented a multi-class classification approach with distinct training and validation datasets.\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl324\slmult1\pardirnatural\partightenfactor0

\f0\b \cf2 Code for Model Training:\

\f1\b0 from tensorflow.keras.models import Sequential\
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\
from tensorflow.keras.preprocessing.image import ImageDataGenerator\
\
data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\
train_gen = data_gen.flow_from_directory(\
    input_dir,\
    target_size=(150, 150),\
    batch_size=32,\
    class_mode='categorical',\
    subset='training'\
)\
val_gen = data_gen.flow_from_directory(\
    input_dir,\
    target_size=(150, 150),\
    batch_size=32,\
    class_mode='categorical',\
    subset='validation'\
)\
\
model = Sequential([\
    Input(shape=(150, 150, 3)),\
    Conv2D(32, (3, 3), activation='relu'),\
    MaxPooling2D((2, 2)),\
    Conv2D(64, (3, 3), activation='relu'),\
    MaxPooling2D((2, 2)),\
    Conv2D(128, (3, 3), activation='relu'),\
    MaxPooling2D((2, 2)),\
    Flatten(),\
    Dense(512, activation='relu'),\
    Dense(num_classes, activation='softmax')\
])\
\
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\
history = model.fit(train_gen, validation_data=val_gen, epochs=20)\
\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 3.	
\f0\b Report Generation:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Developed a comprehensive report including graphs and a detailed table of training metrics for each epoch, such as training and validation accuracy and loss.\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl324\slmult1\pardirnatural\partightenfactor0

\f0\b \cf2 Code for Report Generation:\

\f1\b0 from reportlab.lib.pagesizes import letter\
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle\
from reportlab.lib.styles import getSampleStyleSheet\
from reportlab.lib import colors\
\
def generate_report(history, test_acc, output_dir):\
    doc = SimpleDocTemplate(os.path.join(output_dir, "training_report.pdf"), pagesize=letter)\
    elements = []\
    styles = getSampleStyleSheet()\
    elements.append(Paragraph("Training Report", styles['Title']))\
\
    # Summary of metrics\
    elements.append(Paragraph(f"Test Accuracy: \{test_acc:.2f\}", styles['Normal']))\
\
    # Table of metrics per epoch\
    data = [['Epoch', 'Training Accuracy', 'Validation Accuracy', 'Training Loss', 'Validation Loss']]\
    for i in range(len(history.history['accuracy'])):\
        data.append([\
            i + 1,\
            f"\{history.history['accuracy'][i]:.4f\}",\
            f"\{history.history['val_accuracy'][i]:.4f\}",\
            f"\{history.history['loss'][i]:.4f\}",\
            f"\{history.history['val_loss'][i]:.4f\}"\
        ])\
    table = Table(data)\
    table.setStyle(TableStyle([\
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\
        ('GRID', (0, 0), (-1, -1), 1, colors.black),\
    ]))\
    elements.append(table)\
\
    # Adding the accuracy and loss graphs\
    elements.append(Spacer(1, 12))\
    elements.append(Paragraph("Training Accuracy and Loss Graphs", styles['Heading2']))\
\
    # Save the graphs as images and include in the PDF\
    graph_path = os.path.join(output_dir, "training_graph.png")\
    plt.savefig(graph_path)\
    elements.append(Image(graph_path, width=6*inch, height=3*inch))\
\
    # Save the PDF\
    doc.build(elements)\
    print(f"Report saved at \{os.path.join(output_dir, 'training_report.pdf')\}")\
\
Challenges:\
\
	\'95	Encountered overfitting as indicated by the increasing validation loss while training loss continued to decrease.\
	\'95	Faced difficulties in accurately labeling and categorizing images, particularly in the absence of clear distinctions between some categories.\
\
Advancements:\
\
	\'95	Successfully implemented training for individual classes, which allowed for a more granular understanding of model performance across different site types.\
	\'95	Improved the model evaluation process by generating detailed reports that included epoch-by-epoch analysis, helping in diagnosing issues such as overfitting.\
\
Conclusion:\
The work on July 28, 2024, marked a significant step forward in refining the model\'92s capabilities and understanding its limitations. Moving forward, strategies such as data augmentation and regularization will be explored to mitigate overfitting and improve generalization.\
\
End of Report}