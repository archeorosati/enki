{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 .SFNS-Bold;\f1\fnil\fcharset0 .SFNS-Regular;\f2\froman\fcharset0 TimesNewRomanPSMT;
}
{\colortbl;\red255\green255\blue255;\red14\green14\blue14;}
{\*\expandedcolortbl;;\cssrgb\c6700\c6700\c6700;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl324\slmult1\pardirnatural\partightenfactor0

\f0\b\fs28 \cf2 Report degli Avanzamenti - 30/07/2024
\f1\b0 \
\

\f0\b Obiettivo:
\f1\b0 \
Migliorare il modello di riconoscimento dei siti archeologici utilizzando tecniche di deep learning, con un focus specifico sul miglioramento della gestione delle classi e dell\'92early stopping per prevenire l\'92overfitting.\
\

\f0\b Avanzamenti di Oggi:
\f1\b0 \
\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 	1.	
\f0\b Early Stopping:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Implementato il callback di early stopping per interrompere l\'92addestramento se la validation loss non migliora per 4 epoch consecutivi. Questo aiuta a prevenire l\'92overfitting e ridurre il tempo di addestramento.\
\
from tensorflow.keras.callbacks import EarlyStopping\
\
early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\
\
history = model.fit(\
    train_gen,\
    validation_data=val_gen,\
    epochs=20,\
    callbacks=[early_stopping]\
)\
\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 2.	
\f0\b Generazione del Report:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Aggiornato lo script per generare un report PDF completo con:\
\pard\tqr\tx900\tx1060\li1060\fi-1060\sl324\slmult1\partightenfactor0
\cf2 	\'95	Grafici di accuratezza e perdita.\
	\'95	Una tabella dettagliata dei valori di training e validation loss per ogni epoch.\
\
# Funzione per generare il report\
def generate_report(history, test_acc, output_dir):\
    doc = SimpleDocTemplate(os.path.join(output_dir, "training_report.pdf"), pagesize=letter)\
    elements = []\
    styles = getSampleStyleSheet()\
    elements.append(Paragraph("Training Report", styles['Title']))\
\
    # Summary of metrics\
    elements.append(Paragraph(f"Test Accuracy: \{test_acc:.2f\}", styles['Normal']))\
\
    # Table of metrics per epoch\
    data = [['Epoch', 'Training Accuracy', 'Validation Accuracy', 'Training Loss', 'Validation Loss']]\
    for i in range(len(history.history['accuracy'])):\
        data.append([\
            i + 1,\
            f"\{history.history['accuracy'][i]:.4f\}",\
            f"\{history.history['val_accuracy'][i]:.4f\}",\
            f"\{history.history['loss'][i]:.4f\}",\
            f"\{history.history['val_loss'][i]:.4f\}"\
        ])\
    table = Table(data)\
    table.setStyle(TableStyle([\
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\
        ('GRID', (0, 0), (-1, -1), 1, colors.black),\
    ]))\
    elements.append(table)\
\
    # Adding the accuracy and loss graphs\
    elements.append(Spacer(1, 12))\
    elements.append(Paragraph("Training Accuracy and Loss Graphs", styles['Heading2']))\
\
    # Create plots\
    epochs = np.arange(1, len(history.history['accuracy']) + 1)\
    accuracy = history.history['accuracy']\
    loss = history.history['loss']\
    val_accuracy = history.history['val_accuracy']\
    val_loss = history.history['val_loss']\
\
    plt.figure(figsize=(10, 5))\
\
    # Accuracy plot\
    plt.subplot(1, 2, 1)\
    plt.plot(epochs, accuracy, label='Accuracy')\
    plt.plot(epochs, val_accuracy, label='Val Accuracy')\
    plt.xlabel('Epochs')\
    plt.ylabel('Accuracy')\
    plt.title('Accuracy per Epoch')\
    plt.legend()\
\
    # Loss plot\
    plt.subplot(1, 2, 2)\
    plt.plot(epochs, loss, label='Loss')\
    plt.plot(epochs, val_loss, label='Val Loss')\
    plt.xlabel('Epochs')\
    plt.ylabel('Loss')\
    plt.title('Loss per Epoch')\
    plt.legend()\
\
    # Save plot as image\
    plt.tight_layout()\
    output_dir = '/Users/paolorosati/Library/CloudStorage/GoogleDrive-paolo.rosati@uniroma1.it/Il mio Drive/DesertPASTPilot_dataset1/Reports'\
    if not os.path.exists(output_dir):\
        os.makedirs(output_dir)\
    graph_path = os.path.join(output_dir, "training_graph.png")\
    plt.savefig(graph_path)\
    plt.close()\
\
    elements.append(Image(graph_path, width=6*inch, height=3*inch))\
\
    # Save PDF\
    doc.build(elements)\
    print(f"Report saved at \{os.path.join(output_dir, 'training_report.pdf')\}")\
\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 3.	
\f0\b Analisi della Validation Loss:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Discussione teorica su come dovrebbe fluttuare la curva del validation loss e come interpretare i segnali di overfitting. Sono stati generati due grafici per illustrare:\
\pard\tqr\tx900\tx1060\li1060\fi-1060\sl324\slmult1\partightenfactor0
\cf2 	\'95	Un andamento desiderato della curva del validation loss.\
	\'95	Un esempio di curva del validation loss che mostra overfitting.\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl324\slmult1\pardirnatural\partightenfactor0
\cf2 \

\f0\b Difficolt\'e0 Incontrate:
\f1\b0 \
\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 	1.	
\f0\b Controllo del Numero di Classi:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Problemi nel conteggio del numero di classi presenti nella directory di dati. Il problema \'e8 stato risolto aggiornando il codice per contare dinamicamente le classi presenti.\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 	2.	
\f0\b Errore di Forma dei Dati:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Inizialmente, ci sono stati errori dovuti alla discordanza tra le forme dei target e delle uscite del modello. Questo \'e8 stato risolto assicurandosi che il numero di unit\'e0 nell\'92ultimo strato del modello corrispondesse al numero di classi.\
\pard\tqr\tx260\tx420\li420\fi-420\sl324\slmult1\partightenfactor0

\f2 \cf2 	3.	
\f0\b Early Stopping:
\f1\b0 \
\pard\tqr\tx500\tx660\li660\fi-660\sl324\slmult1\partightenfactor0
\cf2 	\'95	Implementare e verificare l\'92efficacia dell\'92early stopping \'e8 stato cruciale per migliorare l\'92efficienza dell\'92addestramento e prevenire l\'92overfitting.\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl324\slmult1\pardirnatural\partightenfactor0
\cf2 \

\f0\b Conclusioni:
\f1\b0 \
\
Gli avanzamenti di oggi hanno portato significativi miglioramenti nella gestione e ottimizzazione del processo di addestramento del modello, specialmente attraverso l\'92implementazione dell\'92early stopping e la generazione di report dettagliati per l\'92analisi post-addestramento. Questo permette una migliore comprensione delle prestazioni del modello e aiuta a identificare eventuali problemi di overfitting in modo tempestivo.}